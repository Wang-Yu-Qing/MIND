{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import *\n",
    "import json\n",
    "import random\n",
    "import itertools\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch as th\n",
    "\n",
    "\n",
    "class Args:\n",
    "    data_frac = 0.05\n",
    "    min_user_freq = 10\n",
    "    min_book_freq = 10\n",
    "    max_user_freq = 200\n",
    "    train_frac = 0.95\n",
    "    his_len = 100\n",
    "    n_neg = 10\n",
    "\n",
    "    embed_dim = 4\n",
    "    low_cap_dim = 4\n",
    "    high_cap_dim = 4\n",
    "    routing_rounds = 3\n",
    "\n",
    "args = Args()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "valid_users, valid_books = get_valid_user_and_book_set(args)\n",
    "book_cates = read_book_meta(valid_books)\n",
    "valid_cates = set(itertools.chain.from_iterable(list(book_cates.values())))\n",
    "\n",
    "user_encoder, user_decoder = encode_users(valid_users)\n",
    "book_encoder, book_decoder = encode_books(valid_books)\n",
    "cate_encoder, cate_decoder = encode_cates(valid_cates)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_samples = pkl_read('data/test_samples.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[tensor([ 991, 1419], dtype=torch.int32), tensor([[    0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0, 10670,\n",
      "           720,  8137,  6122,  3848, 11125,  9861,  7772,  9289,  8462,  8916,\n",
      "          6065,  1100,  8791,  9993,  6612,  3766,  2207,   985,  1204,  9675,\n",
      "         10062,  2676,   998, 12731,  3525,  4816,  9201,  2549,  7251,  2996,\n",
      "          2709, 11376, 12791,  9222,  7696,  7779,  1578,  3996,  4603,  2121],\n",
      "        [ 8748,  8361,  5610,  8590,  2146,  1289,  4157,   846,  6493, 11486,\n",
      "          7967, 12198,  3308,  3705,  3538, 11498, 10359,  5002,  5921,  9384,\n",
      "         12745, 11250,  6315,  7694,  7278,  9090,  7476,  2912, 10968,  4031,\n",
      "          8807,  3895,  1373,  2657,  5513,  5495,  9452,  9800,   525,  3163,\n",
      "          8664,  4693,  6356,  5948,  3159, 11564,  4139,  1076,  8938,  3173,\n",
      "          4064,  3840, 11469,  3401,  5348,  8272,  2785,  5784,  4859,  9036,\n",
      "         10956,  5746, 10999,   159, 10128,  4657,  1173, 10943, 11372, 10223,\n",
      "           192, 10666,  4037,  1331, 11896,  8183,  4589,  3425,   925,  8793,\n",
      "          1318, 11993, 13026, 11438,  8628,   676, 10403,   815, 10538,  2827,\n",
      "          9428,  7396,  6756,  8849,  4557, 11862, 12664,  7716, 13050,  3615]],\n",
      "       dtype=torch.int32), tensor([2844,  197], dtype=torch.int32), tensor([0., 0.]), tensor([4, 4], dtype=torch.int32)]\n"
     ]
    }
   ],
   "source": [
    "class Dataset:\n",
    "    def __init__(self, samples):\n",
    "        self.samples = samples\n",
    "        self.users, self.histories, self.tars, self.labels, self.cap_nums = [], [], [], [], []\n",
    "        for sample in samples:\n",
    "            self.users.append(sample['user'])\n",
    "            self.histories.append(sample['his'])\n",
    "            self.tars.append(sample['tar'])\n",
    "            self.labels.append(sample['label'])\n",
    "            self.cap_nums.append(sample['cap_num'])\n",
    "        self.users = th.tensor(self.users, dtype=th.int32)\n",
    "        self.histories = th.tensor(self.histories, dtype=th.int32)\n",
    "        self.tars = th.tensor(self.tars, dtype=th.int32)\n",
    "        self.labels = th.tensor(self.labels, dtype=th.float)\n",
    "        self.cap_nums = th.tensor(self.cap_nums, dtype=th.int32)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        return self.users[idx], self.histories[idx], self.tars[idx], self.labels[idx], self.cap_nums[idx]\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.samples)\n",
    "\n",
    "test_dataset = Dataset(test_samples)\n",
    "\n",
    "test_dataloader = \\\n",
    "    th.utils.data.DataLoader(test_dataset, batch_size=2, shuffle=True)\n",
    "\n",
    "for batch in test_dataloader:\n",
    "    print(batch)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Capsule(th.nn.Module):\n",
    "    def __init__(self, ):\n",
    "        pass\n",
    "\n",
    "\n",
    "class MIND(th.nn.Module):\n",
    "    def __init__(self, args, n_users, n_books):\n",
    "        self.embed_dim = args.embed_dim\n",
    "        self.n_caps_high = args.k\n",
    "        self.n_caps_low = args.his_len\n",
    "        # trainable weights\n",
    "        self.user_embeds = th.nn.Embedding(n_users, args.dim)\n",
    "        self.book_embeds = th.nn.Embedding(n_books, args.dim)\n",
    "        self.S = th.nn.Linear(args.low_cap_dim, args.high_cap_dim)\n",
    "    \n",
    "    @staticmethod\n",
    "    def squash(x):\n",
    "        \"\"\"\n",
    "            @x: (batch_size, d)\n",
    "        \"\"\"\n",
    "        l2_norm = th.linalg.norm(x, dim = 1, ord=2) # (batch_size, )\n",
    "        l2_norm_squared = th.pow(l2_norm, 2) # (batch_size, )\n",
    "        scale = l2_norm_squared / (1 + l2_norm_squared) / l2_norm # (batch_size, )\n",
    "\n",
    "        return th.multiply(x, th.unsqueeze(scale, dim=1)) # (batch_size, d)\n",
    "        \n",
    "\n",
    "    def forward(self, batch):\n",
    "        user_id, history, tars, labels, num_caps = batch[0], batch[1], batch[2], batch[3], batch[4]\n",
    "        his_embeds = self.book_embeds(history) # (batch_size, his_len, dim)]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0.1767, 0.1615])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[0.1767, 0.3534, 0.5301, 0.7067],\n",
       "        [0.1777, 0.3554, 0.5330, 0.7107]])"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = th.tensor([[1, 2, 3, 4], [1.1, 2.2, 3.3, 4.4]], dtype=th.float32)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1., 2., 3., 4.],\n",
      "        [1., 2., 3., 4.]])\n",
      "tensor([5.4772, 5.4772])\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "The size of tensor a (4) must match the size of tensor b (2) at non-singleton dimension 1",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/ql/hnsc7cgj6kl1w_vdy3mjn5r40000gn/T/ipykernel_1646/3649561962.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ml2_norm\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mth\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdiv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ml2_norm\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m: The size of tensor a (4) must match the size of tensor b (2) at non-singleton dimension 1"
     ]
    }
   ],
   "source": [
    "print(x)\n",
    "print(l2_norm)\n",
    "th.div(x, l2_norm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([ 0.8032,  0.2930, -0.8113, -0.2308])\n",
      "tensor([1., 1., 1., 1.])\n"
     ]
    }
   ],
   "source": [
    "b = th.tensor([ 0.8032,  0.2930, -0.8113, -0.2308])\n",
    "print(b)\n",
    "print(b / b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.17767943554457133,\n",
       " 0.35535887108914266,\n",
       " 0.533038306633714,\n",
       " 0.7107177421782853]"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import math\n",
    "\n",
    "x = [1.1, 2.2, 3.3, 4.4]\n",
    "\n",
    "l2 = math.sqrt(sum([xx * xx for xx in x]))\n",
    "l2_squred = l2 * l2\n",
    "\n",
    "\n",
    "scale = l2_squred / (1 + l2_squred) / l2\n",
    "\n",
    "[scale * xx for xx in x]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "5.477225575051661"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.10 ('dgl')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "c808db68c8b2bdb007ce37ba3160577cca0b4011c75e61cf50739d44895fcf81"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
