{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import random\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "class Args:\n",
    "    data_frac = 0.3\n",
    "    min_user_freq = 10\n",
    "    min_book_freq = 10\n",
    "    max_user_freq = 200\n",
    "    train_frac = 0.95\n",
    "    his_len = 100\n",
    "    n_neg = 10\n",
    "\n",
    "\n",
    "args = Args()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_valid_user_and_book_set(data_frac):\n",
    "    user_freq, book_freq = {}, {}\n",
    "    with open('data/ratings_Books.csv', 'r') as f:\n",
    "        for line in f.readlines():\n",
    "            if random.random() < data_frac:\n",
    "                # user, item, rating, timestamp\n",
    "                splitted = line.split(\",\")\n",
    "                try:\n",
    "                    user_freq[splitted[0]] += 1\n",
    "                except KeyError:\n",
    "                    user_freq[splitted[0]] = 1\n",
    "                try:\n",
    "                    book_freq[splitted[1]] += 1\n",
    "                except KeyError:\n",
    "                    book_freq[splitted[1]] = 1\n",
    "\n",
    "    valid_users = set([user_id for user_id, cnt in user_freq.items() if cnt >= args.min_user_freq and cnt <= args.max_user_freq])\n",
    "    valid_books = set([book_id for book_id, cnt in book_freq.items() if cnt >= args.min_book_freq])\n",
    "\n",
    "    return valid_users, valid_books\n",
    "    \n",
    "\n",
    "def parse_rating_data(valid_users, valid_books):\n",
    "    user_rates = {}\n",
    "    with open('data/ratings_Books.csv', 'r') as f:\n",
    "        for line in f.readlines():\n",
    "            line = line[:-1]\n",
    "            splitted = line.split(\",\")\n",
    "            user_id, book_id = splitted[0], splitted[1]\n",
    "            if user_id in valid_users and book_id in valid_books:\n",
    "                rate = [user_id, book_id, int(splitted[-1])]\n",
    "                try:\n",
    "                    user_rates[user_id].append(rate)\n",
    "                except KeyError:\n",
    "                    user_rates[user_id] = [rate]\n",
    "    \n",
    "    # convert user ratings to pd.DataFrame for efficient history quering\n",
    "    for user_id, rates in user_rates.items():\n",
    "        user_rates[user_id] = pd.DataFrame(rates, columns=['user_id', 'book_id', 'timestamp']).sort_values(by='timestamp', ignore_index=True)\n",
    "\n",
    "    return user_rates\n",
    "\n",
    "\n",
    "valid_users, valid_books = get_valid_user_and_book_set(args.data_frac)\n",
    "all_user_rates = parse_rating_data(valid_users, valid_books)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_book_meta(valid_books):\n",
    "    book_cates = {}\n",
    "    with open(\"data/meta_Books.json\", \"r\") as f:\n",
    "        for line in f.readlines():\n",
    "            meta = json.loads(line[:-1])\n",
    "            if meta['asin'] in valid_books:\n",
    "                book_cates[meta['asin']] = meta['category']\n",
    "\n",
    "    return book_cates\n",
    "\n",
    "book_cates = read_book_meta(valid_books)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "def encode_users(valid_users):\n",
    "    encoder, decoder = {}, []\n",
    "    encode_id = 0\n",
    "    for user_id in valid_users:\n",
    "        if user_id not in encoder:\n",
    "            encoder[user_id] = encode_id\n",
    "            decoder.append(user_id)\n",
    "            encode_id += 1\n",
    "\n",
    "    return encoder, decoder\n",
    "\n",
    "def encode_books(valid_books):\n",
    "    encoder, decoder = {'<pad>': 0}, ['<pad>']\n",
    "    encode_id = 1\n",
    "    for book_id in valid_books:\n",
    "        if book_id not in encoder:\n",
    "            encoder[book_id] = encode_id\n",
    "            decoder.append(book_id)\n",
    "            encode_id += 1\n",
    "    \n",
    "    return encoder, decoder\n",
    "\n",
    "def encode_cates(book_cates):\n",
    "    encoder, decoder = {'<pad>': 0}, ['<pad>']\n",
    "    encode_id = 1\n",
    "    for cate in book_cates:\n",
    "        if cate not in encoder:\n",
    "            encoder[cate] = encode_id\n",
    "            decoder.append(cate)\n",
    "            encode_id += 1\n",
    "    \n",
    "    return encoder, decoder\n",
    "\n",
    "\n",
    "user_encoder, user_decoder = encode_users(valid_users)\n",
    "book_encoder, book_decoder = encode_books(valid_books)\n",
    "cate_encoder, cate_decoder = encode_cates(valid_cates)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "89"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cate_decoder[89]\n",
    "cate_encoder['Certification']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Each rating action reflect user's interest upon that book, so each rating action is one postive sample.\n",
    "2. Split all the rating actions to 19:1 as described in the paper.\n",
    "3. From each rating action, use that user's rating actions before the current rating time as history behaviors.\n",
    "4. For negative samples, keep the history behavior same as the positive sample, but randomly draw target books from the whole book pool."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_train_and_test_rates(user_rates, train_frac):\n",
    "    all_train_ratings, all_test_ratings = [], []\n",
    "    for user_id, ratings in user_rates.items():\n",
    "        train_rates = ratings.sample(frac=train_frac, replace=False)\n",
    "        test_rates = ratings.drop(train_rates.index)\n",
    "\n",
    "        for rate in train_rates.values: all_train_ratings.append(rate)\n",
    "        for rate in test_rates.values: all_test_ratings.append(rate)\n",
    "    \n",
    "    return all_train_ratings, all_test_ratings\n",
    "\n",
    "all_train_rates, all_test_rates = split_train_and_test_rates(all_user_rates, args.train_frac)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pad_or_cut(seq, length):\n",
    "    if len(seq) > length:\n",
    "        # cut the front\n",
    "        # len(seq) - 1 - x + 1 = length --> x = len(seq) - length\n",
    "        return seq[len(seq) - length:]\n",
    "    else:\n",
    "        return np.concatenate((seq, np.array([0] * (length - len(seq)))))\n",
    "\n",
    "\n",
    "def query_history_books(user_id, timestamp, user_rates, his_len):\n",
    "    bool_idx = user_rates['timestamp'] < timestamp\n",
    "    history_books = user_rates['timestamp'].loc[bool_idx, ['book_id']].values\n",
    "    if len(history_books) != his_len:\n",
    "        history_books = pad_or_cut(history_books, his_len)\n",
    "\n",
    "    return history_books\n",
    "\n",
    "\n",
    "def build_samples(rates, all_user_rates, valid_books, args):\n",
    "    samples = []\n",
    "    candidates = list(valid_books)\n",
    "    for rate in rates:\n",
    "        his = query_history_books(rate[0], rate[2], all_user_rates[rate[0]], args.his_len)\n",
    "        tar = rate[1]\n",
    "        samples.append({'his': his, 'tar': tar, 'label': 1})\n",
    "        # negative sampling\n",
    "        neg_tar = random.choices(candidates, k = args.n_neg)\n",
    "        for tar in neg_tar:\n",
    "            samples.append({'his': his, 'tar': tar, 'label': 0})\n",
    "    \n",
    "    return samples\n",
    "\n",
    "train_samples = build_samples(all_train_rates, all_user_rates)\n",
    "test_samples = build_samples(all_test_rates, all_user_rates, valid_books, args)\n",
    "\n",
    "        \n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['030726646X',\n",
       " '1491521775',\n",
       " 'B009VSDN42',\n",
       " '0979622808',\n",
       " 'B0073WA85U',\n",
       " '1607148439',\n",
       " '0823014010',\n",
       " '1555838197',\n",
       " '141698271X',\n",
       " '0989180204']"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random.choices(list(valid_books), k = 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 0, 0])"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "k\n",
    "pad = np.array([0] * 5)\n",
    "pad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['0099994003', '0684844419', '1585670111', '0375701613',\n",
       "       '0465057128', 0, 0, 0, 0, 0], dtype=object)"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.concatenate((a, pad))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.10 ('dgl')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "c808db68c8b2bdb007ce37ba3160577cca0b4011c75e61cf50739d44895fcf81"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
